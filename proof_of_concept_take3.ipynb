{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "import haversine\n",
    "import Levenshtein\n",
    "from fuzzywuzzy import process\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Montana Traffic Count Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#browser = webdriver.Firefox()\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "browser = webdriver.PhantomJS()\n",
    "browser.get('https://mdt.maps.arcgis.com/home/webmap/viewer.html?webmap=8a0308abed8846b6b533781e7a96eedd&extent=-116.2848,43.146,-103.8043,50.0897')\n",
    "# try:\n",
    "#     element = WebDriverWait(driver, 5).until(\n",
    "#         EC.presence_of_element_located((By.ID, \"legendContentButtons\"))\n",
    "#     )\n",
    "#     print(element.text)\n",
    "# finally:\n",
    "#     driver.quit()\n",
    "# #driver.save_screenshot('screen.png')\n",
    "# #driver.find_element_by_name('body').text\n",
    "\n",
    "browser.find_element_by_id('webmap-details-legend-content').click()\n",
    "browser.find_element_by_id('Traffic_7588_tableTool').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scrape data\n",
    "row_ids = []\n",
    "row_soup = []\n",
    "new_height = 0\n",
    "while new_height < 357500:\n",
    "#while new_height:\n",
    "    height = browser.find_elements_by_class_name('dgrid-scroller')[0]\n",
    "    browser.execute_script('arguments[0].scrollTop = {}'.format(str(new_height)), height)\n",
    "    sleep(2)\n",
    "    \n",
    "    browser.page_source\n",
    "    soup = bs(browser.page_source, 'html.parser')\n",
    "    rows = bs.findAll(soup, 'div', attrs = {'class': 'dgrid-row'})\n",
    "    for row in rows:\n",
    "        if row.attrs['id'] not in row_ids:\n",
    "            row_ids += [row.attrs['id']]\n",
    "            row_soup += [row]\n",
    "    new_height += 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract labels\n",
    "col_labels = []\n",
    "fields = row_soup[0].findAll('td')\n",
    "for field in fields:\n",
    "    label = field.attrs['class'][3].split(\"-\")[1]\n",
    "    col_labels.append(label)\n",
    "\n",
    "# convert to dataframe    \n",
    "t_counts = []\n",
    "for row in row_soup:\n",
    "    fields = row.findAll('td')\n",
    "    t_counts.append([td.text for td in fields])\n",
    "t_counts = pd.DataFrame(t_counts, columns=col_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_counts = pd.read_csv('./t_counts2.csv', index_col=False)\n",
    "t_counts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get long and lat from MT api\n",
    "# prob could have used for original data dl\n",
    "# but didnt know it existed\n",
    "locations = []\n",
    "url_start = 'https://app.mdt.mt.gov/arcgis/rest/services/Standard/Traffic/MapServer/1/query?where=&text=&objectIds='\n",
    "sep = \"%2C+\"\n",
    "url_end = '&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&relationParam=&outFields=&returnGeometry=true&returnTrueCurves=false&maxAllowableOffset=&geometryPrecision=&outSR=&returnIdsOnly=false&returnCountOnly=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&returnZ=false&returnM=false&gdbVersion=&returnDistinctValues=false&resultOffset=&resultRecordCount=&queryByDistance=&returnExtentsOnly=false&datumTransformation=&parameterValues=&rangeValues=&f=geojson'\n",
    "batch = 0\n",
    "\n",
    "print(len(t_counts.OBJECTID))\n",
    "\n",
    "while batch <= len(t_counts.OBJECTID):\n",
    "    ids = sep.join(str(t_counts.OBJECTID[batch:batch+100]))\n",
    "    url = url_start + ids + url_end\n",
    "    request = requests.get(url)\n",
    "    print(ids)\n",
    "    print(url)\n",
    "    print(request.json()['features'])\n",
    "    print()\n",
    "    print()\n",
    "    try:\n",
    "        for point in request.json()['features']:\n",
    "            row = [point['properties']['SITE_ID']]\n",
    "            row += point['geometry']['coordinates']\n",
    "            locations.append(row)\n",
    "        batch += 100\n",
    "    except KeyError as ke: \n",
    "        print(ke)\n",
    "        print(batch)\n",
    "        break\n",
    "#         print('Ignoring KeyError - reason \"%s\"'% str(ke))\n",
    "#         print(request.json())\n",
    "locations = pd.DataFrame(locations, columns=['SITE_ID', 'LONGITUDE', 'LATITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_counts = pd.merge(t_counts, locations, on = 'SITE_ID')\n",
    "print(t_counts.shape)\n",
    "t_counts.drop_duplicates(subset='SITE_ID', inplace=True)\n",
    "print(t_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(t_counts, open('./t_counts.sav', 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_counts_orig = t_counts.copy()\n",
    "t_counts = t_counts.iloc[:500,].copy()\n",
    "# counties_orig = counties.copy()\n",
    "# counties = counties.iloc[:500,].copy()\n",
    "# counties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_counts['ROAD'] = t_counts.DESCRIPTIO.str.split(',').str[0].str.lower()\n",
    "t_counts['f_index'] = list(range(len(t_counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def google_maps(row):\n",
    "    maps_apis = ['AIzaSyB0YYbVOtzZozg168Ea4mIcsnx_ok0YSqQ',\n",
    "                 'AIzaSyBTAKkAWQdmAHOF3L29Q7uQ6zC_68vekMw',\n",
    "                 'AIzaSyAjPKe0tXolqwp-sAHGG9ba8RKFBz3w0uE',\n",
    "                 'AIzaSyACjXxPJkzcTS8cS_9uAXjn6enLLYHsfzc']\n",
    "    \n",
    "    url_base = 'https://maps.googleapis.com/maps/api/geocode/json?latlng='\n",
    "    url_end = '&key='\n",
    "    lon = str(row.LONGITUDE)\n",
    "    lat = str(row.LATITUDE)\n",
    "    \n",
    "    try:\n",
    "        for i, api_key in enumerate(maps_apis):\n",
    "            if row.f_index < ((i + 1) * 2450):\n",
    "                break\n",
    "        api_key = 'AIzaSyB0YYbVOtzZozg168Ea4mIcsnx_ok0YSqQ'\n",
    "        url = url_base + lat +\",\"+lon+url_end+api_key\n",
    "        maps = requests.get(url)\n",
    "        #response[row.f_index] = maps.json()\n",
    "        long_name = maps.json()['results'][0]['address_components'][1]['long_name']\n",
    "        short_name = maps.json()['results'][0]['address_components'][1]['short_name']\n",
    "        county_1 = maps.json()['results'][0]['address_components'][3]['long_name']\n",
    "        county_2 = maps.json()['results'][0]['address_components'][4]['long_name']\n",
    "        print([row.f_index, long_name, short_name, county_1, county_2])\n",
    "        return([row.f_index, long_name, short_name, county_1, county_2])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return [row.f_index] + [np.nan] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counties = t_counts.apply(google_maps, axis = 1)\n",
    "counties = pd.DataFrame([x for x in counties], columns=['f_index','road_long','road_short', 'county1','county2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counties = pd.read_csv('./counties.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_county(row):\n",
    "    order = ['county2', 'county1', 'road_short', 'road_long']\n",
    "    \n",
    "    for i, r in enumerate(order):\n",
    "        if row[r] == 'Montana':\n",
    "            col = order[i + 1]\n",
    "            break\n",
    "    else:\n",
    "        for i, r in enumerate(order):\n",
    "            if row[r] == 'United States':\n",
    "                col = order[i + 1]\n",
    "                break\n",
    "        else:\n",
    "            col = order[0]\n",
    "    return row[col]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counties['county_extract'] = counties.apply(extract_county, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_counts = pd.merge(t_counts, counties, how = 'left', on = 'f_index')\n",
    "t_counts = t_counts[pd.isnull(t_counts.county1)== False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop nulls from important fields\n",
    "stops = pd.read_csv('./MT-clean.csv')\n",
    "stops = stops[pd.isnull(stops.violation) == False]\n",
    "stops = stops[stops.violation.str.contains('Speeding')]\n",
    "stops = stops[pd.isnull(stops.lat) == False]\n",
    "stops = stops[pd.isnull(stops.lon) == False]\n",
    "stops = stops[pd.isnull(stops.fine_grained_location) == False]\n",
    "stops['stop_date'] = pd.to_datetime(stops.stop_date, errors='coerce')\n",
    "stops['year'] = stops.stop_date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops_orig = stops.copy()\n",
    "stops = stops.iloc[:10000,].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_counties = stops.county_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_counts['county_match'] = t_counts.apply(lambda x: process.extractOne(x.county_extract, stop_counties)[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = [col for col in t_counts.columns if col.startswith('AADT')]\n",
    "reduced_counts = pd.melt(t_counts[counts + ['SITE_ID']], id_vars=['SITE_ID'])\n",
    "reduced_counts['year'] = (str(20) + reduced_counts.variable.str[-2:]).apply(lambda x: int(x))\n",
    "reduced_counts.drop('variable', axis = 1, inplace = True)\n",
    "reduced_counts.rename(columns={'value':'traffic_count'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduced_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nearest_loc(row, miles = 15):\n",
    "    # compute distance to each count location in miles\n",
    "    stop_loc = (row.lat, row.lon)\n",
    "    just_county = t_counts[t_counts.county_match == row.county_name]\n",
    "    distances = just_county.apply(lambda x: haversine.haversine(stop_loc, (x.LATITUDE, x.LONGITUDE), miles = True), axis = 1)\n",
    "\n",
    " \n",
    "    # filter to within range and compute z\n",
    "    distances = distances[distances <= 15]\n",
    "   \n",
    "    if len(distances) == 0:\n",
    "        #return \"stamp0\"\n",
    "        return np.nan\n",
    "    elif len(distances) == 1:\n",
    "        tmp = int(distances.index.item())\n",
    "        #print(t_counts.loc[tmp].SITE_ID)\n",
    "        #return t_counts.loc[distances.index].SITE_ID\n",
    "        return t_counts.loc[tmp].SITE_ID\n",
    "    else:\n",
    "        distances = (distances - distances.mean())/distances.std()\n",
    "        distances = abs(distances[distances <= 0])\n",
    "        if len(distances) == 1:\n",
    "            #original\n",
    "            #t_counts.loc[distances.index].SITE_ID\n",
    "            tmp = int(distances.index.item())\n",
    "            #print(t_counts.loc[tmp].SITE_ID)\n",
    "            return t_counts.loc[tmp].SITE_ID\n",
    "        elif len(distances) == 0:\n",
    "            #return \"stamp1\"\n",
    "            return np.nan \n",
    "        \n",
    "    \n",
    "    # find Levenshtein distance between stop locations\n",
    "    lev = t_counts.loc[distances.index].apply(lambda x: Levenshtein.distance(x.ROAD, row.fine_grained_location.lower()), axis = 1)\n",
    "    lev = (lev - lev.mean())/lev.std()\n",
    "    lev = abs(lev[lev <= 0])\n",
    "\n",
    "    # take average of two measures and return best score\n",
    "    possibles = pd.concat([distances,lev], axis = 1).dropna().mean(axis = 1)\n",
    "\n",
    "    if len(possibles) <= 0:\n",
    "        #return \"stamp2\"\n",
    "        return np.nan\n",
    "    return t_counts.loc[possibles.idxmax()].SITE_ID "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import haversine\n",
    "import Levenshtein\n",
    "from fuzzywuzzy import process\n",
    "import pickle\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import pyspark\n",
    "import pyspark.sql\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"myAppName\")\n",
    "sqlContext = SQLContext(sc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "schemaStops = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"stop_date\", StringType(), True),\n",
    "    StructField(\"stop_time\", StringType(), True),\n",
    "    StructField(\"location_raw\", StringType(), True),\n",
    "    StructField(\"county_name\", StringType(), True),\n",
    "    StructField(\"county_fips\", StringType(), True),\n",
    "    StructField(\"fine_grained_location\", StringType(), True),\n",
    "    StructField(\"police_department\", StringType(), True),\n",
    "    StructField(\"driver_gender\", StringType(), True),\n",
    "    StructField(\"driver_age_raw\", FloatType(), True),\n",
    "    StructField(\"driver_age\", FloatType(), True),\n",
    "    StructField(\"driver_race_raw\", StringType(), True),\n",
    "    StructField(\"driver_race\", StringType(), True),\n",
    "    StructField(\"violation_raw\", StringType(), True),\n",
    "    StructField(\"violation\", StringType(), True),\n",
    "    StructField(\"search_conducted\", StringType(), True),\n",
    "    StructField(\"search_type_raw\", StringType(), True),\n",
    "    StructField(\"search_type\", StringType(), True),\n",
    "    StructField(\"contraband_found\", StringType(), True),\n",
    "    StructField(\"stop_outcome\", StringType(), True),\n",
    "    StructField(\"is_arrested\", StringType(), True),\n",
    "    StructField(\"lat\", FloatType(), True),\n",
    "    StructField(\"lon\", FloatType(), True),\n",
    "    StructField(\"ethnicity\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"out_of_state\", StringType(), True),\n",
    "    StructField(\"vehicle_year\", StringType(), True),\n",
    "    StructField(\"vehicle_make\", StringType(), True),\n",
    "    StructField(\"vehicle_model\", StringType(), True),\n",
    "    StructField(\"vehicle_style\", StringType(), True),\n",
    "    StructField(\"search_reason\", StringType(), True),\n",
    "    StructField(\"stop_outcome_raw\", StringType(), True),\n",
    "    StructField(\"year\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "schemaTcounts = StructType([\n",
    "    StructField(\"SITE_ID\", StringType(), True),\n",
    "    StructField(\"DESCRIPTIO\", StringType(), True),\n",
    "    StructField(\"DEPT_ROUTE\", StringType(), True),\n",
    "    StructField(\"COR_ROUTE\", StringType(), True),\n",
    "    StructField(\"REF_POINT\", StringType(), True),\n",
    "    StructField(\"COUNTY\", StringType(), True),\n",
    "    StructField(\"OWNER\", StringType(), True),\n",
    "    StructField(\"SITE_TYPE\", StringType(), True),\n",
    "    StructField(\"ATR_WIM\", StringType(), True),\n",
    "    StructField(\"VEHICLE_CL\", StringType(), True),\n",
    "    StructField(\"AADT_08\", StringType(), True),\n",
    "    StructField(\"SOURCE_08\", StringType(), True),\n",
    "    StructField(\"AADT_09\", StringType(), True),\n",
    "    StructField(\"SOURCE_09\", StringType(), True),\n",
    "    StructField(\"AADT_10\", StringType(), True),\n",
    "    StructField(\"SOURCE_10\", StringType(), True),\n",
    "    StructField(\"AADT_11\", StringType(), True),\n",
    "    StructField(\"SOURCE_11\", StringType(), True),\n",
    "    StructField(\"AADT_12\", StringType(), True),\n",
    "    StructField(\"SOURCE_12\", StringType(), True),\n",
    "    StructField(\"AADT_13\", StringType(), True),\n",
    "    StructField(\"SOURCE_13\", StringType(), True),   \n",
    "    StructField(\"AADT_14\", StringType(), True),\n",
    "    StructField(\"SOURCE_14\", StringType(), True),    \n",
    "    StructField(\"AADT_15\", StringType(), True),\n",
    "    StructField(\"SOURCE_15\", StringType(), True),  \n",
    "    StructField(\"AADT_16\", StringType(), True),\n",
    "    StructField(\"SOURCE_16\", StringType(), True),\n",
    "    StructField(\"OBJECTID\", StringType(), True),\n",
    "    StructField(\"LONGITUDE\", FloatType(), True),\n",
    "    StructField(\"LATITUDE\", FloatType(), True),\n",
    "    StructField(\"ROAD\", StringType(), True),\n",
    "    StructField(\"Unnamed: 0\", StringType(), True),\n",
    "    StructField(\"f_index\", IntegerType(), True),\n",
    "    StructField(\"road_long\", StringType(), True),\n",
    "    StructField(\"road_short\", StringType(), True),\n",
    "    StructField(\"county1\", StringType(), True),\n",
    "    StructField(\"county2\", StringType(), True),\n",
    "    StructField(\"county_extract\", StringType(), True),\n",
    "    StructField(\"county_match\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5909, 40)\n",
      "(540932, 34)\n"
     ]
    }
   ],
   "source": [
    "stops = pd.read_csv('./stops_pre_apply.csv')\n",
    "t_counts = pd.read_csv('./t_counts_pre_apply.csv')\n",
    "print(t_counts.shape)\n",
    "print(stops.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>state</th>\n",
       "      <th>stop_date</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>location_raw</th>\n",
       "      <th>county_name</th>\n",
       "      <th>county_fips</th>\n",
       "      <th>fine_grained_location</th>\n",
       "      <th>police_department</th>\n",
       "      <th>driver_gender</th>\n",
       "      <th>...</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>city</th>\n",
       "      <th>out_of_state</th>\n",
       "      <th>vehicle_year</th>\n",
       "      <th>vehicle_make</th>\n",
       "      <th>vehicle_model</th>\n",
       "      <th>vehicle_style</th>\n",
       "      <th>search_reason</th>\n",
       "      <th>stop_outcome_raw</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MT-2009-00003</td>\n",
       "      <td>MT</td>\n",
       "      <td>2009-01-03</td>\n",
       "      <td>11:36</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>Missoula County</td>\n",
       "      <td>30063.0</td>\n",
       "      <td>P007 HWY 93 MM 77 N/B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1999</td>\n",
       "      <td>GMC</td>\n",
       "      <td>YUKON</td>\n",
       "      <td>SPORT UTILITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INFFRACTION ARREST</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MT-2009-00004</td>\n",
       "      <td>MT</td>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>10:33</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>Missoula County</td>\n",
       "      <td>30063.0</td>\n",
       "      <td>P007 HWY 93 MM 81 S/B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2002</td>\n",
       "      <td>HOND</td>\n",
       "      <td>CR-V</td>\n",
       "      <td>SPORT UTILITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INFFRACTION ARREST</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MT-2009-00005</td>\n",
       "      <td>MT</td>\n",
       "      <td>2009-01-04</td>\n",
       "      <td>10:46</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>Missoula County</td>\n",
       "      <td>30063.0</td>\n",
       "      <td>P007 HWY 93 MM 81 N/B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1992</td>\n",
       "      <td>TOYT</td>\n",
       "      <td>TERCEL</td>\n",
       "      <td>SEDAN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INFFRACTION ARREST</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MT-2009-00008</td>\n",
       "      <td>MT</td>\n",
       "      <td>2009-01-05</td>\n",
       "      <td>15:32</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>Missoula County</td>\n",
       "      <td>30063.0</td>\n",
       "      <td>P007 HWY 93 MM 79 S/B</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>2004</td>\n",
       "      <td>GMC</td>\n",
       "      <td>YUK</td>\n",
       "      <td>SPORT UTILITY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>INFFRACTION ARREST</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MT-2009-00009</td>\n",
       "      <td>MT</td>\n",
       "      <td>2009-01-06</td>\n",
       "      <td>16:45</td>\n",
       "      <td>YELLOWSTONE</td>\n",
       "      <td>Yellowstone County</td>\n",
       "      <td>30111.0</td>\n",
       "      <td>INTERSECTION OF HWY 312 &amp; SHEPHERD ROAD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>...</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1992</td>\n",
       "      <td>BMW</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TRAFFIC CITATION</td>\n",
       "      <td>2009.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              id state   stop_date stop_time location_raw         county_name  \\\n",
       "0  MT-2009-00003    MT  2009-01-03     11:36     MISSOULA     Missoula County   \n",
       "1  MT-2009-00004    MT  2009-01-04     10:33     MISSOULA     Missoula County   \n",
       "2  MT-2009-00005    MT  2009-01-04     10:46     MISSOULA     Missoula County   \n",
       "3  MT-2009-00008    MT  2009-01-05     15:32     MISSOULA     Missoula County   \n",
       "4  MT-2009-00009    MT  2009-01-06     16:45  YELLOWSTONE  Yellowstone County   \n",
       "\n",
       "   county_fips                    fine_grained_location  police_department  \\\n",
       "0      30063.0                    P007 HWY 93 MM 77 N/B                NaN   \n",
       "1      30063.0                    P007 HWY 93 MM 81 S/B                NaN   \n",
       "2      30063.0                    P007 HWY 93 MM 81 N/B                NaN   \n",
       "3      30063.0                    P007 HWY 93 MM 79 S/B                NaN   \n",
       "4      30111.0  INTERSECTION OF HWY 312 & SHEPHERD ROAD                NaN   \n",
       "\n",
       "  driver_gender   ...    ethnicity  city out_of_state vehicle_year  \\\n",
       "0             M   ...            N   NaN        False         1999   \n",
       "1             F   ...          NaN   NaN        False         2002   \n",
       "2             M   ...          NaN   NaN        False         1992   \n",
       "3             F   ...          NaN   NaN        False         2004   \n",
       "4             M   ...            N   NaN        False         1992   \n",
       "\n",
       "  vehicle_make vehicle_model  vehicle_style search_reason    stop_outcome_raw  \\\n",
       "0          GMC         YUKON  SPORT UTILITY           NaN  INFFRACTION ARREST   \n",
       "1         HOND          CR-V  SPORT UTILITY           NaN  INFFRACTION ARREST   \n",
       "2         TOYT        TERCEL          SEDAN           NaN  INFFRACTION ARREST   \n",
       "3          GMC           YUK  SPORT UTILITY           NaN  INFFRACTION ARREST   \n",
       "4          BMW           NaN             4D           NaN    TRAFFIC CITATION   \n",
       "\n",
       "     year  \n",
       "0  2009.0  \n",
       "1  2009.0  \n",
       "2  2009.0  \n",
       "3  2009.0  \n",
       "4  2009.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopsRDD = sqlContext.createDataFrame(stops,schemaStops)\n",
    "smallStopsRDD = sqlContext.createDataFrame(stops.iloc[:5,],schemaStops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540932\n",
      "5909\n"
     ]
    }
   ],
   "source": [
    "t_countsRDD = sqlContext.createDataFrame(t_counts,schemaTcounts)\n",
    "print(stopsRDD.count())\n",
    "print(t_countsRDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nearest_loc_spark(row):\n",
    "    # compute distance to each count location in miles\n",
    "    stop_loc = (row.lat, row.lon)\n",
    "    \n",
    "    return t_countsRDD.filter(lambda x: x[39] == row.county_name.collect())\n",
    "    \n",
    "#     just_county = t_counts[t_counts.county_match == row.county_name]\n",
    "    \n",
    "    \n",
    "#     distances = just_county.apply(lambda x: haversine.haversine(stop_loc, (x.LATITUDE, x.LONGITUDE), miles = True), axis = 1)\n",
    "\n",
    " \n",
    "#     # filter to within range and compute z\n",
    "#     distances = distances[distances <= 15]\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test = smallStopsRDD.map(lambda row:  find_nearest_loc_spark(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Missoula County\n",
       "Name: county_name, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops.county_name.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o43.filter.\n: java.lang.RuntimeException: [1.15] failure: identifier expected\n\ncounty_match == 'Missoula County'\n              ^\n\tat scala.sys.package$.error(package.scala:27)\n\tat org.apache.spark.sql.catalyst.SqlParser$.parseExpression(SqlParser.scala:49)\n\tat org.apache.spark.sql.DataFrame.filter(DataFrame.scala:768)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:748)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-35618dd1eda0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_countsRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"county_match == 'Missoula County'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, condition)\u001b[0m\n\u001b[1;32m    898\u001b[0m         \"\"\"\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcondition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    811\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         return_value = get_return_value(\n\u001b[0;32m--> 813\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.9-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    306\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    307\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    309\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o43.filter.\n: java.lang.RuntimeException: [1.15] failure: identifier expected\n\ncounty_match == 'Missoula County'\n              ^\n\tat scala.sys.package$.error(package.scala:27)\n\tat org.apache.spark.sql.catalyst.SqlParser$.parseExpression(SqlParser.scala:49)\n\tat org.apache.spark.sql.DataFrame.filter(DataFrame.scala:768)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:231)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:381)\n\tat py4j.Gateway.invoke(Gateway.java:259)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:133)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:209)\n\tat java.lang.Thread.run(Thread.java:748)\n"
     ]
    }
   ],
   "source": [
    "t_countsRDD.filter(\"[] == 'Missoula County'\").collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test.count()\n",
    "test.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ab']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([\"ab\", \"cd\", \"ef\", \"gh\", \"tt\"])\n",
    "rdd.filter(lambda x: x == 'ab').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops['SITE_ID'] = stops.apply(find_nearest_loc, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stops.to_csv('montana_stops.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.isnull(stops.SITE_ID).sum() / len(stops) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_site_id(row):\n",
    "    s = row.SITE_ID\n",
    "    \n",
    "    if type(s) == np.ndarray:\n",
    "        return s[0]\n",
    "    else:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops['SITE_ID'] = stops.apply(fix_site_id, axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops_reduced = pd.DataFrame(stops.iloc[0:10,].groupby(['SITE_ID','year']).size()).reset_index()\n",
    "stops_reduced.rename(columns={0:'stops'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = pd.merge(stops_reduced, reduced_counts, how = 'outer', on = ['SITE_ID', 'year'])\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_t_count(row):\n",
    "    t = row.traffic_count\n",
    "    try:\n",
    "        n = int(\"\".join([x for x in t if x != \",\"]))\n",
    "        return n\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined['traffic_count'] = combined.apply(fix_t_count,axis = 1)\n",
    "combined = combined.groupby('SITE_ID').mean().dropna()\n",
    "combined['stop_rate'] = combined.stops/combined.traffic_count\n",
    "combined.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined.sort_values('stop_rate', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = pd.merge(combined, t_counts[['SITE_ID', 'LONGITUDE','LATITUDE','DESCRIPTIO', 'county_match']], how = 'left', on = 'SITE_ID')\n",
    "combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combined = pd.merge(combined, t_counts[['SITE_ID','DESCRIPTIO', 'county_match']], how = 'left', on = 'SITE_ID')\n",
    "# combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuts = np.percentile(combined.stop_rate, np.linspace(0,100,11))\n",
    "combined['stop_rate_group_10p'] = pd.cut(combined.stop_rate, bins=cuts, labels=[x for x in range(1,11)])\n",
    "combined.stop_rate_group_10p.fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = pd.merge(stops, combined[['SITE_ID', 'stop_rate']], how = 'left', on = 'SITE_ID')\n",
    "stops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, show, output_notebook\n",
    "from bokeh.models import (\n",
    "  GMapPlot, GMapOptions, ColumnDataSource, Circle, \n",
    "    DataRange1d, PanTool, WheelZoomTool, BoxSelectTool, \n",
    "    ZoomInTool,ZoomOutTool, HoverTool\n",
    ")\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump(combined, open('./combined.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = pickle.load(open('./combined.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined.stop_rate_group_10p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output_notebook()\n",
    "map_options = GMapOptions(lat=45, lng=-110, map_type=\"roadmap\", zoom=6)\n",
    "\n",
    "plot = GMapPlot(\n",
    "    x_range=DataRange1d(), y_range=DataRange1d(), map_options=map_options\n",
    ")\n",
    "plot.api_key = 'AIzaSyBxQH93QnURqVD3jluRMvqbQCAbzzNVwnU'\n",
    "#plot.title.text = \"Montana Speed Traps\"\n",
    "colors = [\n",
    "    \"#%02x%02x%02x\" % (int(r), int(g), int(b)) for r, g, b, _ in 255*plt.cm.inferno(mpl.colors.Normalize()(combined.stop_rate_group_10p))\n",
    "]\n",
    "circle = Circle(x=\"lon\", y=\"lat\", size=6, fill_color='col', fill_alpha=0.8, line_color=None)\n",
    "\n",
    "source = ColumnDataSource(\n",
    "    data=dict(\n",
    "        lat=combined.LATITUDE,\n",
    "        lon=combined.LONGITUDE,\n",
    "        col=colors,\n",
    "         street=combined.DESCRIPTIO,\n",
    "         county=combined.county_match,\n",
    "         t_count = combined.traffic_count,\n",
    "        stops = combined.stops\n",
    "#        rating = combined.stop_rate_group_10p\n",
    "    )\n",
    ")\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Location\", \"@street\"),\n",
    "    (\"County\", \"@county\"),\n",
    "    (\"Stops\", \"@stops\"),\n",
    "    (\"Traffic Count\", \"@t_count\")\n",
    "    #(\"Rating\", \"@rating\")\n",
    "])\n",
    "\n",
    "plot.add_glyph(source, circle)\n",
    "plot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool(), ZoomInTool(), ZoomOutTool(), hover)\n",
    "output_file(\"montana.html\")\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
