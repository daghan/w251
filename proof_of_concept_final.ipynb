{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from time import sleep\n",
    "import requests\n",
    "import json\n",
    "import haversine\n",
    "import Levenshtein\n",
    "from fuzzywuzzy import process\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Montana Traffic Count Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "#browser = webdriver.Firefox()\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "browser = webdriver.PhantomJS()\n",
    "browser.get('https://mdt.maps.arcgis.com/home/webmap/viewer.html?webmap=8a0308abed8846b6b533781e7a96eedd&extent=-116.2848,43.146,-103.8043,50.0897')\n",
    "# try:\n",
    "#     element = WebDriverWait(driver, 5).until(\n",
    "#         EC.presence_of_element_located((By.ID, \"legendContentButtons\"))\n",
    "#     )\n",
    "#     print(element.text)\n",
    "# finally:\n",
    "#     driver.quit()\n",
    "# #driver.save_screenshot('screen.png')\n",
    "# #driver.find_element_by_name('body').text\n",
    "\n",
    "browser.find_element_by_id('webmap-details-legend-content').click()\n",
    "browser.find_element_by_id('Traffic_7588_tableTool').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scrape data\n",
    "row_ids = []\n",
    "row_soup = []\n",
    "new_height = 0\n",
    "while new_height < 357500:\n",
    "#while new_height:\n",
    "    height = browser.find_elements_by_class_name('dgrid-scroller')[0]\n",
    "    browser.execute_script('arguments[0].scrollTop = {}'.format(str(new_height)), height)\n",
    "    sleep(2)\n",
    "    \n",
    "    browser.page_source\n",
    "    soup = bs(browser.page_source, 'html.parser')\n",
    "    rows = bs.findAll(soup, 'div', attrs = {'class': 'dgrid-row'})\n",
    "    for row in rows:\n",
    "        if row.attrs['id'] not in row_ids:\n",
    "            row_ids += [row.attrs['id']]\n",
    "            row_soup += [row]\n",
    "    new_height += 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract labels\n",
    "col_labels = []\n",
    "fields = row_soup[0].findAll('td')\n",
    "for field in fields:\n",
    "    label = field.attrs['class'][3].split(\"-\")[1]\n",
    "    col_labels.append(label)\n",
    "\n",
    "# convert to dataframe    \n",
    "t_counts = []\n",
    "for row in row_soup:\n",
    "    fields = row.findAll('td')\n",
    "    t_counts.append([td.text for td in fields])\n",
    "t_counts = pd.DataFrame(t_counts, columns=col_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_counts = pd.read_csv('./t_counts2.csv', index_col=False)\n",
    "t_counts.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get long and lat from MT api\n",
    "# prob could have used for original data dl\n",
    "# but didnt know it existed\n",
    "locations = []\n",
    "url_start = 'https://app.mdt.mt.gov/arcgis/rest/services/Standard/Traffic/MapServer/1/query?where=&text=&objectIds='\n",
    "sep = \"%2C+\"\n",
    "url_end = '&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&relationParam=&outFields=&returnGeometry=true&returnTrueCurves=false&maxAllowableOffset=&geometryPrecision=&outSR=&returnIdsOnly=false&returnCountOnly=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&returnZ=false&returnM=false&gdbVersion=&returnDistinctValues=false&resultOffset=&resultRecordCount=&queryByDistance=&returnExtentsOnly=false&datumTransformation=&parameterValues=&rangeValues=&f=geojson'\n",
    "batch = 0\n",
    "\n",
    "print(len(t_counts.OBJECTID))\n",
    "\n",
    "while batch <= len(t_counts.OBJECTID):\n",
    "    ids = sep.join(str(t_counts.OBJECTID[batch:batch+100]))\n",
    "    url = url_start + ids + url_end\n",
    "    request = requests.get(url)\n",
    "    print(ids)\n",
    "    print(url)\n",
    "    print(request.json()['features'])\n",
    "    print()\n",
    "    print()\n",
    "    try:\n",
    "        for point in request.json()['features']:\n",
    "            row = [point['properties']['SITE_ID']]\n",
    "            row += point['geometry']['coordinates']\n",
    "            locations.append(row)\n",
    "        batch += 100\n",
    "    except KeyError as ke: \n",
    "        print(ke)\n",
    "        print(batch)\n",
    "        break\n",
    "#         print('Ignoring KeyError - reason \"%s\"'% str(ke))\n",
    "#         print(request.json())\n",
    "locations = pd.DataFrame(locations, columns=['SITE_ID', 'LONGITUDE', 'LATITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_counts = pd.merge(t_counts, locations, on = 'SITE_ID')\n",
    "print(t_counts.shape)\n",
    "t_counts.drop_duplicates(subset='SITE_ID', inplace=True)\n",
    "print(t_counts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(t_counts, open('./t_counts.sav', 'wb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t_counts_orig = t_counts.copy()\n",
    "t_counts = t_counts.iloc[:500,].copy()\n",
    "# counties_orig = counties.copy()\n",
    "# counties = counties.iloc[:500,].copy()\n",
    "# counties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_counts['ROAD'] = t_counts.DESCRIPTIO.str.split(',').str[0].str.lower()\n",
    "t_counts['f_index'] = list(range(len(t_counts)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def google_maps(row):\n",
    "    maps_apis = []\n",
    "    \n",
    "    url_base = 'https://maps.googleapis.com/maps/api/geocode/json?latlng='\n",
    "    url_end = '&key='\n",
    "    lon = str(row.LONGITUDE)\n",
    "    lat = str(row.LATITUDE)\n",
    "    \n",
    "    try:\n",
    "        for i, api_key in enumerate(maps_apis):\n",
    "            if row.f_index < ((i + 1) * 2450):\n",
    "                break\n",
    "        \n",
    "        url = url_base + lat +\",\"+lon+url_end+api_key\n",
    "        maps = requests.get(url)\n",
    "        #response[row.f_index] = maps.json()\n",
    "        long_name = maps.json()['results'][0]['address_components'][1]['long_name']\n",
    "        short_name = maps.json()['results'][0]['address_components'][1]['short_name']\n",
    "        county_1 = maps.json()['results'][0]['address_components'][3]['long_name']\n",
    "        county_2 = maps.json()['results'][0]['address_components'][4]['long_name']\n",
    "        print([row.f_index, long_name, short_name, county_1, county_2])\n",
    "        return([row.f_index, long_name, short_name, county_1, county_2])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return [row.f_index] + [np.nan] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counties = t_counts.apply(google_maps, axis = 1)\n",
    "counties = pd.DataFrame([x for x in counties], columns=['f_index','road_long','road_short', 'county1','county2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counties = pd.read_csv('./counties.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_county(row):\n",
    "    order = ['county2', 'county1', 'road_short', 'road_long']\n",
    "    \n",
    "    for i, r in enumerate(order):\n",
    "        if row[r] == 'Montana':\n",
    "            col = order[i + 1]\n",
    "            break\n",
    "    else:\n",
    "        for i, r in enumerate(order):\n",
    "            if row[r] == 'United States':\n",
    "                col = order[i + 1]\n",
    "                break\n",
    "        else:\n",
    "            col = order[0]\n",
    "    return row[col]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counties['county_extract'] = counties.apply(extract_county, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_counts = pd.merge(t_counts, counties, how = 'left', on = 'f_index')\n",
    "t_counts = t_counts[pd.isnull(t_counts.county1)== False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop nulls from important fields\n",
    "stops = pd.read_csv('./MT-clean.csv')\n",
    "stops = stops[pd.isnull(stops.violation) == False]\n",
    "stops = stops[stops.violation.str.contains('Speeding')]\n",
    "stops = stops[pd.isnull(stops.lat) == False]\n",
    "stops = stops[pd.isnull(stops.lon) == False]\n",
    "stops = stops[pd.isnull(stops.fine_grained_location) == False]\n",
    "stops['stop_date'] = pd.to_datetime(stops.stop_date, errors='coerce')\n",
    "stops['year'] = stops.stop_date.dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops_orig = stops.copy()\n",
    "stops = stops.iloc[:10000,].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_counties = stops.county_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_counts['county_match'] = t_counts.apply(lambda x: process.extractOne(x.county_extract, stop_counties)[0], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts = [col for col in t_counts.columns if col.startswith('AADT')]\n",
    "reduced_counts = pd.melt(t_counts[counts + ['SITE_ID']], id_vars=['SITE_ID'])\n",
    "reduced_counts['year'] = (str(20) + reduced_counts.variable.str[-2:]).apply(lambda x: int(x))\n",
    "reduced_counts.drop('variable', axis = 1, inplace = True)\n",
    "reduced_counts.rename(columns={'value':'traffic_count'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reduced_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nearest_loc(row, miles = 15):\n",
    "    # compute distance to each count location in miles\n",
    "    stop_loc = (row.lat, row.lon)\n",
    "    just_county = t_counts[t_counts.county_match == row.county_name]\n",
    "    distances = just_county.apply(lambda x: haversine.haversine(stop_loc, (x.LATITUDE, x.LONGITUDE), miles = True), axis = 1)\n",
    "\n",
    " \n",
    "    # filter to within range and compute z\n",
    "    distances = distances[distances <= 15]\n",
    "   \n",
    "    if len(distances) == 0:\n",
    "        #return \"stamp0\"\n",
    "        return np.nan\n",
    "    elif len(distances) == 1:\n",
    "        tmp = int(distances.index.item())\n",
    "        #print(t_counts.loc[tmp].SITE_ID)\n",
    "        #return t_counts.loc[distances.index].SITE_ID\n",
    "        return t_counts.loc[tmp].SITE_ID\n",
    "    else:\n",
    "        distances = (distances - distances.mean())/distances.std()\n",
    "        distances = abs(distances[distances <= 0])\n",
    "        if len(distances) == 1:\n",
    "            #original\n",
    "            #t_counts.loc[distances.index].SITE_ID\n",
    "            tmp = int(distances.index.item())\n",
    "            #print(t_counts.loc[tmp].SITE_ID)\n",
    "            return t_counts.loc[tmp].SITE_ID\n",
    "        elif len(distances) == 0:\n",
    "            #return \"stamp1\"\n",
    "            return np.nan \n",
    "        \n",
    "    \n",
    "    # find Levenshtein distance between stop locations\n",
    "    lev = t_counts.loc[distances.index].apply(lambda x: Levenshtein.distance(x.ROAD, row.fine_grained_location.lower()), axis = 1)\n",
    "    lev = (lev - lev.mean())/lev.std()\n",
    "    lev = abs(lev[lev <= 0])\n",
    "\n",
    "    # take average of two measures and return best score\n",
    "    possibles = pd.concat([distances,lev], axis = 1).dropna().mean(axis = 1)\n",
    "\n",
    "    if len(possibles) <= 0:\n",
    "        #return \"stamp2\"\n",
    "        return np.nan\n",
    "    return t_counts.loc[possibles.idxmax()].SITE_ID "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark code starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import haversine\n",
    "import Levenshtein\n",
    "from fuzzywuzzy import process\n",
    "import pickle\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyspark\n",
    "import pyspark.sql\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Word Count\") \\\n",
    "    .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    ">>> from pyspark.conf import SparkConf\n",
    ">>> SparkSession.builder.config(conf=SparkConf())\n",
    "<pyspark.sql.session...\n",
    "\n",
    "\n",
    "sc = pyspark.SparkContext(appName=\"myAppName\")\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "schemaStops = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"stop_date\", StringType(), True),\n",
    "    StructField(\"stop_time\", StringType(), True),\n",
    "    StructField(\"location_raw\", StringType(), True),\n",
    "    StructField(\"county_name\", StringType(), True),\n",
    "    StructField(\"county_fips\", StringType(), True),\n",
    "    StructField(\"fine_grained_location\", StringType(), True),\n",
    "    StructField(\"police_department\", StringType(), True),\n",
    "    StructField(\"driver_gender\", StringType(), True),\n",
    "    StructField(\"driver_age_raw\", FloatType(), True),\n",
    "    StructField(\"driver_age\", FloatType(), True),\n",
    "    StructField(\"driver_race_raw\", StringType(), True),\n",
    "    StructField(\"driver_race\", StringType(), True),\n",
    "    StructField(\"violation_raw\", StringType(), True),\n",
    "    StructField(\"violation\", StringType(), True),\n",
    "    StructField(\"search_conducted\", StringType(), True),\n",
    "    StructField(\"search_type_raw\", StringType(), True),\n",
    "    StructField(\"search_type\", StringType(), True),\n",
    "    StructField(\"contraband_found\", StringType(), True),\n",
    "    StructField(\"stop_outcome\", StringType(), True),\n",
    "    StructField(\"is_arrested\", StringType(), True),\n",
    "    StructField(\"lat\", FloatType(), True),\n",
    "    StructField(\"lon\", FloatType(), True),\n",
    "    StructField(\"ethnicity\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"out_of_state\", StringType(), True),\n",
    "    StructField(\"vehicle_year\", StringType(), True),\n",
    "    StructField(\"vehicle_make\", StringType(), True),\n",
    "    StructField(\"vehicle_model\", StringType(), True),\n",
    "    StructField(\"vehicle_style\", StringType(), True),\n",
    "    StructField(\"search_reason\", StringType(), True),\n",
    "    StructField(\"stop_outcome_raw\", StringType(), True),\n",
    "    StructField(\"year\", StringType(), True)\n",
    "])\n",
    "\n",
    "\n",
    "schemaTcounts = StructType([\n",
    "    StructField(\"SITE_ID\", StringType(), True),\n",
    "    StructField(\"DESCRIPTIO\", StringType(), True),\n",
    "    StructField(\"DEPT_ROUTE\", StringType(), True),\n",
    "    StructField(\"COR_ROUTE\", StringType(), True),\n",
    "    StructField(\"REF_POINT\", StringType(), True),\n",
    "    StructField(\"COUNTY\", StringType(), True),\n",
    "    StructField(\"OWNER\", StringType(), True),\n",
    "    StructField(\"SITE_TYPE\", StringType(), True),\n",
    "    StructField(\"ATR_WIM\", StringType(), True),\n",
    "    StructField(\"VEHICLE_CL\", StringType(), True),\n",
    "    StructField(\"AADT_08\", StringType(), True),\n",
    "    StructField(\"SOURCE_08\", StringType(), True),\n",
    "    StructField(\"AADT_09\", StringType(), True),\n",
    "    StructField(\"SOURCE_09\", StringType(), True),\n",
    "    StructField(\"AADT_10\", StringType(), True),\n",
    "    StructField(\"SOURCE_10\", StringType(), True),\n",
    "    StructField(\"AADT_11\", StringType(), True),\n",
    "    StructField(\"SOURCE_11\", StringType(), True),\n",
    "    StructField(\"AADT_12\", StringType(), True),\n",
    "    StructField(\"SOURCE_12\", StringType(), True),\n",
    "    StructField(\"AADT_13\", StringType(), True),\n",
    "    StructField(\"SOURCE_13\", StringType(), True),   \n",
    "    StructField(\"AADT_14\", StringType(), True),\n",
    "    StructField(\"SOURCE_14\", StringType(), True),    \n",
    "    StructField(\"AADT_15\", StringType(), True),\n",
    "    StructField(\"SOURCE_15\", StringType(), True),  \n",
    "    StructField(\"AADT_16\", StringType(), True),\n",
    "    StructField(\"SOURCE_16\", StringType(), True),\n",
    "    StructField(\"OBJECTID\", StringType(), True),\n",
    "    StructField(\"LONGITUDE\", FloatType(), True),\n",
    "    StructField(\"LATITUDE\", FloatType(), True),\n",
    "    StructField(\"ROAD\", StringType(), True),\n",
    "    StructField(\"Unnamed: 0\", StringType(), True),\n",
    "    StructField(\"f_index\", IntegerType(), True),\n",
    "    StructField(\"road_long\", StringType(), True),\n",
    "    StructField(\"road_short\", StringType(), True),\n",
    "    StructField(\"county1\", StringType(), True),\n",
    "    StructField(\"county2\", StringType(), True),\n",
    "    StructField(\"county_extract\", StringType(), True),\n",
    "    StructField(\"county_match\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (26,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5909, 40)\n",
      "(540932, 34)\n"
     ]
    }
   ],
   "source": [
    "stops = pd.read_csv('./stops_pre_apply.csv')\n",
    "t_counts = pd.read_csv('./t_counts_pre_apply.csv')\n",
    "print(t_counts.shape)\n",
    "print(stops.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SITE_ID</th>\n",
       "      <th>DESCRIPTIO</th>\n",
       "      <th>DEPT_ROUTE</th>\n",
       "      <th>COR_ROUTE</th>\n",
       "      <th>REF_POINT</th>\n",
       "      <th>COUNTY</th>\n",
       "      <th>OWNER</th>\n",
       "      <th>SITE_TYPE</th>\n",
       "      <th>ATR_WIM</th>\n",
       "      <th>VEHICLE_CL</th>\n",
       "      <th>...</th>\n",
       "      <th>LATITUDE</th>\n",
       "      <th>ROAD</th>\n",
       "      <th>f_index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>road_long</th>\n",
       "      <th>road_short</th>\n",
       "      <th>county1</th>\n",
       "      <th>county2</th>\n",
       "      <th>county_extract</th>\n",
       "      <th>county_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43-5-005</td>\n",
       "      <td>MONTANA 16,  081+0.205, 7.5 mi N of US 2 (Culb...</td>\n",
       "      <td>N-22E</td>\n",
       "      <td>C000022E</td>\n",
       "      <td>081+0.205</td>\n",
       "      <td>ROOSEVELT</td>\n",
       "      <td>MDT</td>\n",
       "      <td>Short Term Count Site</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>...</td>\n",
       "      <td>48.254165</td>\n",
       "      <td>montana 16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Montana 16</td>\n",
       "      <td>MT-16</td>\n",
       "      <td>Roosevelt County</td>\n",
       "      <td>Montana</td>\n",
       "      <td>Roosevelt County</td>\n",
       "      <td>Roosevelt County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25-7B-018</td>\n",
       "      <td>ROUTE 430,  003+0.176, E of Valley Dr</td>\n",
       "      <td>U-5818E</td>\n",
       "      <td>C000430E</td>\n",
       "      <td>003+0.176</td>\n",
       "      <td>LEWIS &amp; CLARK</td>\n",
       "      <td>COUNTY</td>\n",
       "      <td>Short Term Count Site</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>46.616988</td>\n",
       "      <td>route 430</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Canyon Ferry Road</td>\n",
       "      <td>Canyon Ferry Rd</td>\n",
       "      <td>Lewis and Clark County</td>\n",
       "      <td>Montana</td>\n",
       "      <td>Lewis and Clark County</td>\n",
       "      <td>Lewis And Clark County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32-3A-159</td>\n",
       "      <td>S 5TH ST W,  000+0.227,  btwn Catlin &amp; Garfield</td>\n",
       "      <td>L-32-4564N</td>\n",
       "      <td>C006028W</td>\n",
       "      <td>000+0.227</td>\n",
       "      <td>MISSOULA</td>\n",
       "      <td>CITY</td>\n",
       "      <td>Short Term Count Site</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>46.865046</td>\n",
       "      <td>s 5th st w</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>South 5th Street West</td>\n",
       "      <td>S 5th St W</td>\n",
       "      <td>Missoula</td>\n",
       "      <td>Missoula County</td>\n",
       "      <td>Missoula County</td>\n",
       "      <td>Missoula County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14-3-015</td>\n",
       "      <td>MONTANA 81,  013+0.212,  btwn Ketchner &amp; Knerr...</td>\n",
       "      <td>P-81E</td>\n",
       "      <td>C000081E</td>\n",
       "      <td>013+0.212</td>\n",
       "      <td>FERGUS</td>\n",
       "      <td>MDT</td>\n",
       "      <td>Short Term Count Site</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>47.319414</td>\n",
       "      <td>montana 81</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Broadway Avenue</td>\n",
       "      <td>MT-81</td>\n",
       "      <td>Fergus County</td>\n",
       "      <td>Montana</td>\n",
       "      <td>Fergus County</td>\n",
       "      <td>Fergus County</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16-3-014</td>\n",
       "      <td>MAIN ST,  019+0.793,  E of Jackrabbit Ln (Belg...</td>\n",
       "      <td>N-205E</td>\n",
       "      <td>C000205E</td>\n",
       "      <td>019+0.793</td>\n",
       "      <td>GALLATIN</td>\n",
       "      <td>MDT</td>\n",
       "      <td>Short Term Count Site</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>45.779610</td>\n",
       "      <td>main st</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>West Main Street</td>\n",
       "      <td>W Main St</td>\n",
       "      <td>Gallatin County</td>\n",
       "      <td>Montana</td>\n",
       "      <td>Gallatin County</td>\n",
       "      <td>Gallatin County</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SITE_ID                                         DESCRIPTIO  DEPT_ROUTE  \\\n",
       "0   43-5-005  MONTANA 16,  081+0.205, 7.5 mi N of US 2 (Culb...       N-22E   \n",
       "1  25-7B-018              ROUTE 430,  003+0.176, E of Valley Dr     U-5818E   \n",
       "2  32-3A-159    S 5TH ST W,  000+0.227,  btwn Catlin & Garfield  L-32-4564N   \n",
       "3   14-3-015  MONTANA 81,  013+0.212,  btwn Ketchner & Knerr...       P-81E   \n",
       "4   16-3-014  MAIN ST,  019+0.793,  E of Jackrabbit Ln (Belg...      N-205E   \n",
       "\n",
       "  COR_ROUTE   REF_POINT         COUNTY   OWNER              SITE_TYPE ATR_WIM  \\\n",
       "0  C000022E   081+0.205      ROOSEVELT     MDT  Short Term Count Site     NaN   \n",
       "1  C000430E   003+0.176  LEWIS & CLARK  COUNTY  Short Term Count Site     NaN   \n",
       "2  C006028W   000+0.227       MISSOULA    CITY  Short Term Count Site     NaN   \n",
       "3  C000081E   013+0.212         FERGUS     MDT  Short Term Count Site     NaN   \n",
       "4  C000205E   019+0.793       GALLATIN     MDT  Short Term Count Site     NaN   \n",
       "\n",
       "  VEHICLE_CL           ...             LATITUDE        ROAD f_index  \\\n",
       "0          Y           ...            48.254165  montana 16       0   \n",
       "1        NaN           ...            46.616988   route 430       1   \n",
       "2        NaN           ...            46.865046  s 5th st w       2   \n",
       "3        NaN           ...            47.319414  montana 81       3   \n",
       "4        NaN           ...            45.779610     main st       4   \n",
       "\n",
       "  Unnamed: 0              road_long       road_short                 county1  \\\n",
       "0          0             Montana 16            MT-16        Roosevelt County   \n",
       "1          1      Canyon Ferry Road  Canyon Ferry Rd  Lewis and Clark County   \n",
       "2          2  South 5th Street West       S 5th St W                Missoula   \n",
       "3          3        Broadway Avenue            MT-81           Fergus County   \n",
       "4          4       West Main Street        W Main St         Gallatin County   \n",
       "\n",
       "           county2          county_extract            county_match  \n",
       "0          Montana        Roosevelt County        Roosevelt County  \n",
       "1          Montana  Lewis and Clark County  Lewis And Clark County  \n",
       "2  Missoula County         Missoula County         Missoula County  \n",
       "3          Montana           Fergus County           Fergus County  \n",
       "4          Montana         Gallatin County         Gallatin County  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b146b9eee024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#stopsRDD = sqlContext.createDataFrame(stops,schemaStops)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msmallStopsRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreateDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mschemaStops\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "#stopsRDD = sqlContext.createDataFrame(stops,schemaStops)\n",
    "\n",
    "smallStopsRDD = spark.createDataFrame(stops.iloc[:5,],schemaStops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540932\n",
      "5909\n"
     ]
    }
   ],
   "source": [
    "t_countsRDD = sqlContext.createDataFrame(t_counts,schemaTcounts)\n",
    "print(stopsRDD.count())\n",
    "print(t_countsRDD.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-e4bfa429de88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_countsRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/manual/spark-2.2.0-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1018\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             raise AttributeError(\n\u001b[0;32m-> 1020\u001b[0;31m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[0m\u001b[1;32m   1021\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "t_countsRDD.map(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_nearest_loc_spark(row, miles = 15):\n",
    "    stop_loc = (row.lat, row.lon)\n",
    "    distancesList = t_countsRDD.filter(t_countsRDD.county_match.like(row.county_name))\\\n",
    "    .map(lambda x: haversine.haversine(stop_loc, (x.LATITUDE, x.LONGITUDE), miles = True))\\\n",
    "    .collect()\n",
    "    distances = pd.DataFrame(distancesList)\n",
    "    #distances = distances[distances <= 15].dropna()\n",
    "    distances = distances[distances <= 15]\n",
    "    \n",
    "    if len(distances) == 0:\n",
    "        #return \"stamp0\"\n",
    "        return np.nan\n",
    "    elif len(distances) == 1:\n",
    "        tmp = int(distances.index.item())\n",
    "        \n",
    "        #print(t_counts.loc[tmp].SITE_ID)\n",
    "        #return t_counts.loc[distances.index].SITE_ID\n",
    "        return t_counts.loc[tmp].SITE_ID\n",
    "    else:\n",
    "        distances = (distances - distances.mean())/distances.std()\n",
    "        distances = abs(distances[distances <= 0])\n",
    "        if len(distances) == 1:\n",
    "            #original\n",
    "            #t_counts.loc[distances.index].SITE_ID\n",
    "            tmp = int(distances.index.item())\n",
    "            #print(t_counts.loc[tmp].SITE_ID)\n",
    "            return t_counts.loc[tmp].SITE_ID\n",
    "        elif len(distances) == 0:\n",
    "            #return \"stamp1\"\n",
    "            return np.nan \n",
    "        \n",
    "    \n",
    "    # find Levenshtein distance between stop locations\n",
    "    lev = t_counts.loc[distances.index].apply(lambda x: Levenshtein.distance(x.ROAD, row.fine_grained_location.lower()), axis = 1)\n",
    "    lev = (lev - lev.mean())/lev.std()\n",
    "    lev = abs(lev[lev <= 0])\n",
    "\n",
    "    # take average of two measures and return best score\n",
    "    possibles = pd.concat([distances,lev], axis = 1).dropna().mean(axis = 1)\n",
    "\n",
    "    if len(possibles) <= 0:\n",
    "        #return \"stamp2\"\n",
    "        return np.nan\n",
    "    return t_counts.loc[possibles.idxmax()].SITE_ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stops['SITE_ID'] = stops.apply(find_nearest_loc, axis = 1)\n",
    "ttt = stopsRDD.map(lambda row:  find_nearest_loc_spark(row)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "row = stops.iloc[1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.stat import Statistics\n",
    "\n",
    "stop_loc = (row.lat, row.lon)\n",
    "distancesList = t_countsRDD.filter(t_countsRDD.county_match.like(row.county_name))\\\n",
    "                    .map(lambda x: haversine.haversine(stop_loc, (x.LATITUDE, x.LONGITUDE), miles = True))\\\n",
    "                    .collect()\n",
    "distances = pd.DataFrame(distancesList)\n",
    "#distances = distances[distances <= 15].dropna()\n",
    "distances = distances[distances <= 15]\n",
    "\n",
    "if len(distances) == 0:\n",
    "    #return \"stamp0\"\n",
    "    print(np.nan)\n",
    "elif len(distances) == 1:\n",
    "    print(distances.index.item())\n",
    "else:\n",
    "    distances = (distances - distances.mean())/distances.std()\n",
    "    distances = abs(distances[distances <= 0])\n",
    "    max_index = distances.index.max()\n",
    "    min_index = distances.index.min()\n",
    "    levRDD = t_countsRDD.filter(t_countsRDD.f_index >= min_index)\\\n",
    "            .filter(t_countsRDD.f_index <= max_index)\\\n",
    "            .map(lambda x: Levenshtein.distance(str(x.ROAD), row.fine_grained_location.lower()))\n",
    "    \n",
    "    lev = pd.DataFrame(levRDD.collect())\n",
    "    lev = (lev - lev.mean())/lev.std()\n",
    "    lev = abs(lev[lev <= 0])\n",
    "    possibles = pd.concat([distances,lev], axis = 1).dropna().mean(axis = 1)\n",
    "    if len(possibles) <= 0:\n",
    "        #return \"stamp2\"\n",
    "        print(np.nan)\n",
    "    possible_index = possibles.idxmax()\n",
    "    print(possible_index)\n",
    "    print(t_countsRDD.filter(t_countsRDD.f_index == possible_index)\\\n",
    "            .map(lambda x: x.SITE_ID).collect())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(t_countsRDD.take(5)).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#stops.to_csv('montana_stops.csv')\n",
    "stops=stopsRDD.toPandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.isnull(stops.SITE_ID).sum() / len(stops) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_site_id(row):\n",
    "    s = row.SITE_ID\n",
    "    \n",
    "    if type(s) == np.ndarray:\n",
    "        return s[0]\n",
    "    else:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops['SITE_ID'] = stops.apply(fix_site_id, axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops_reduced = pd.DataFrame(stops.iloc[0:10,].groupby(['SITE_ID','year']).size()).reset_index()\n",
    "stops_reduced.rename(columns={0:'stops'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = pd.merge(stops_reduced, reduced_counts, how = 'outer', on = ['SITE_ID', 'year'])\n",
    "combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fix_t_count(row):\n",
    "    t = row.traffic_count\n",
    "    try:\n",
    "        n = int(\"\".join([x for x in t if x != \",\"]))\n",
    "        return n\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined['traffic_count'] = combined.apply(fix_t_count,axis = 1)\n",
    "combined = combined.groupby('SITE_ID').mean().dropna()\n",
    "combined['stop_rate'] = combined.stops/combined.traffic_count\n",
    "combined.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined.sort_values('stop_rate', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = pd.merge(combined, t_counts[['SITE_ID', 'LONGITUDE','LATITUDE','DESCRIPTIO', 'county_match']], how = 'left', on = 'SITE_ID')\n",
    "combined.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combined = pd.merge(combined, t_counts[['SITE_ID','DESCRIPTIO', 'county_match']], how = 'left', on = 'SITE_ID')\n",
    "# combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuts = np.percentile(combined.stop_rate, np.linspace(0,100,11))\n",
    "combined['stop_rate_group_10p'] = pd.cut(combined.stop_rate, bins=cuts, labels=[x for x in range(1,11)])\n",
    "combined.stop_rate_group_10p.fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stops = pd.merge(stops, combined[['SITE_ID', 'stop_rate']], how = 'left', on = 'SITE_ID')\n",
    "stops.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bokeh.io import output_file, show, output_notebook\n",
    "from bokeh.models import (\n",
    "  GMapPlot, GMapOptions, ColumnDataSource, Circle, \n",
    "    DataRange1d, PanTool, WheelZoomTool, BoxSelectTool, \n",
    "    ZoomInTool,ZoomOutTool, HoverTool\n",
    ")\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#pickle.dump(combined, open('./combined.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = pickle.load(open('./combined.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined.stop_rate_group_10p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#output_notebook()\n",
    "map_options = GMapOptions(lat=45, lng=-110, map_type=\"roadmap\", zoom=6)\n",
    "\n",
    "plot = GMapPlot(\n",
    "    x_range=DataRange1d(), y_range=DataRange1d(), map_options=map_options\n",
    ")\n",
    "plot.api_key = 'AIzaSyBxQH93QnURqVD3jluRMvqbQCAbzzNVwnU'\n",
    "#plot.title.text = \"Montana Speed Traps\"\n",
    "colors = [\n",
    "    \"#%02x%02x%02x\" % (int(r), int(g), int(b)) for r, g, b, _ in 255*plt.cm.inferno(mpl.colors.Normalize()(combined.stop_rate_group_10p))\n",
    "]\n",
    "circle = Circle(x=\"lon\", y=\"lat\", size=6, fill_color='col', fill_alpha=0.8, line_color=None)\n",
    "\n",
    "source = ColumnDataSource(\n",
    "    data=dict(\n",
    "        lat=combined.LATITUDE,\n",
    "        lon=combined.LONGITUDE,\n",
    "        col=colors,\n",
    "         street=combined.DESCRIPTIO,\n",
    "         county=combined.county_match,\n",
    "         t_count = combined.traffic_count,\n",
    "        stops = combined.stops\n",
    "#        rating = combined.stop_rate_group_10p\n",
    "    )\n",
    ")\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Location\", \"@street\"),\n",
    "    (\"County\", \"@county\"),\n",
    "    (\"Stops\", \"@stops\"),\n",
    "    (\"Traffic Count\", \"@t_count\")\n",
    "    #(\"Rating\", \"@rating\")\n",
    "])\n",
    "\n",
    "plot.add_glyph(source, circle)\n",
    "plot.add_tools(PanTool(), WheelZoomTool(), BoxSelectTool(), ZoomInTool(), ZoomOutTool(), hover)\n",
    "output_file(\"montana.html\")\n",
    "\n",
    "show(plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
